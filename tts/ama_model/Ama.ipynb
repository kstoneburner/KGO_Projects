{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29a8693a",
   "metadata": {},
   "source": [
    "Reference Notebook\n",
    "https://colab.research.google.com/github/coqui-ai/TTS/blob/main/notebooks/Tutorial_2_train_your_first_TTS_model.ipynb#scrollTo=014879b7-f18d-44c0-b24a-e10f8002113a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f741bab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# BaseDatasetConfig: defines name, formatter and path of the dataset.\n",
    "from TTS.tts.configs.shared_configs import BaseDatasetConfig\n",
    "\n",
    "#//*** create model output path if needed\n",
    "output_path = \"tts_train_dir\"\n",
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d305ce3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"tts_train_dir\"\n",
    "output_path = os.path.join(os.path.join(os.getcwd(), output_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cca899fa",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": " [!] No training samples found in C:\\Users\\stonk013\\KGO_Projects\\tts\\ama_model\\tts_train_dir\\wavs/",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 11\u001b[0m\n\u001b[0;32m      6\u001b[0m dataset_config \u001b[38;5;241m=\u001b[39m BaseDatasetConfig(\n\u001b[0;32m      7\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvctk\u001b[39m\u001b[38;5;124m\"\u001b[39m, meta_file_train\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m, language\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124men-us\u001b[39m\u001b[38;5;124m\"\u001b[39m, path\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(output_path,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwavs\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m      8\u001b[0m )\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# load training samples\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m train_samples, eval_samples \u001b[38;5;241m=\u001b[39m load_tts_samples(dataset_config, eval_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\KGO_Projects\\tts\\TTS\\TTS\\tts\\datasets\\__init__.py:121\u001b[0m, in \u001b[0;36mload_tts_samples\u001b[1;34m(datasets, eval_split, formatter, eval_split_max_size, eval_split_size)\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[38;5;66;03m# load train set\u001b[39;00m\n\u001b[0;32m    120\u001b[0m meta_data_train \u001b[38;5;241m=\u001b[39m formatter(root_path, meta_file_train, ignored_speakers\u001b[38;5;241m=\u001b[39mignored_speakers)\n\u001b[1;32m--> 121\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(meta_data_train) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m [!] No training samples found in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mroot_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmeta_file_train\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    123\u001b[0m meta_data_train \u001b[38;5;241m=\u001b[39m add_extra_keys(meta_data_train, language, dataset_name)\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m | > Found \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(meta_data_train)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m files in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mPath(root_path)\u001b[38;5;241m.\u001b[39mresolve()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAssertionError\u001b[0m:  [!] No training samples found in C:\\Users\\stonk013\\KGO_Projects\\tts\\ama_model\\tts_train_dir\\wavs/"
     ]
    }
   ],
   "source": [
    "from TTS.tts.configs.shared_configs import BaseDatasetConfig\n",
    "from TTS.tts.datasets import load_tts_samples\n",
    "\n",
    "\n",
    "# dataset config for one of the pre-defined datasets\n",
    "dataset_config = BaseDatasetConfig(\n",
    "    formatter=\"vctk\", meta_file_train=\"\", language=\"en-us\", path=os.path.join(os.path.join(output_path,\"wavs\"))\n",
    ")\n",
    "\n",
    "# load training samples\n",
    "train_samples, eval_samples = load_tts_samples(dataset_config, eval_split=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6693a3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Setting up Audio Processor...\n",
      " | > sample_rate:22050\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log10\n",
      " | > min_level_db:-100\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:20\n",
      " | > fft_size:1024\n",
      " | > power:1.5\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:60\n",
      " | > signal_norm:True\n",
      " | > symmetric_norm:True\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:None\n",
      " | > pitch_fmin:1.0\n",
      " | > pitch_fmax:640.0\n",
      " | > spec_gain:20.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:4.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:True\n",
      " | > trim_db:45\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:None\n",
      " | > base:10\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n"
     ]
    }
   ],
   "source": [
    "# GlowTTSConfig: all model related values for training, validating and testing.\n",
    "from TTS.tts.configs.glow_tts_config import GlowTTSConfig\n",
    "config = GlowTTSConfig(\n",
    "    batch_size=32,\n",
    "    eval_batch_size=16,\n",
    "    num_loader_workers=4,\n",
    "    num_eval_loader_workers=4,\n",
    "    run_eval=True,\n",
    "    test_delay_epochs=-1,\n",
    "    epochs=100,\n",
    "    text_cleaner=\"phoneme_cleaners\",\n",
    "    use_phonemes=True,\n",
    "    phoneme_language=\"en-us\",\n",
    "    phoneme_cache_path=os.path.join(output_path, \"phoneme_cache\"),\n",
    "    print_step=25,\n",
    "    print_eval=False,\n",
    "    mixed_precision=True,\n",
    "    output_path=output_path,\n",
    "    datasets=[dataset_config],\n",
    "    save_step=1000,\n",
    ")\n",
    "\n",
    "from TTS.utils.audio import AudioProcessor\n",
    "ap = AudioProcessor.init_from_config(config)\n",
    "# Modify sample rate if for a custom audio dataset:\n",
    "# ap.sample_rate = 22050"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b1515b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from TTS.tts.utils.text.tokenizer import TTSTokenizer\n",
    "tokenizer, config = TTSTokenizer.init_from_config(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b30495a",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mTTS\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtts\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_tts_samples\n\u001b[1;32m----> 2\u001b[0m train_samples, eval_samples \u001b[38;5;241m=\u001b[39m load_tts_samples(\n\u001b[0;32m      3\u001b[0m     dataset_config,\n\u001b[0;32m      4\u001b[0m     eval_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m      5\u001b[0m     eval_split_max_size\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39meval_split_max_size,\n\u001b[0;32m      6\u001b[0m     eval_split_size\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39meval_split_size,\n\u001b[0;32m      7\u001b[0m )\n",
      "File \u001b[1;32m~\\KGO_Projects\\tts\\TTS\\TTS\\tts\\datasets\\__init__.py:120\u001b[0m, in \u001b[0;36mload_tts_samples\u001b[1;34m(datasets, eval_split, formatter, eval_split_max_size, eval_split_size)\u001b[0m\n\u001b[0;32m    118\u001b[0m     formatter \u001b[38;5;241m=\u001b[39m _get_formatter_by_name(formatter_name)\n\u001b[0;32m    119\u001b[0m \u001b[38;5;66;03m# load train set\u001b[39;00m\n\u001b[1;32m--> 120\u001b[0m meta_data_train \u001b[38;5;241m=\u001b[39m formatter(root_path, meta_file_train, ignored_speakers\u001b[38;5;241m=\u001b[39mignored_speakers)\n\u001b[0;32m    121\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(meta_data_train) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m [!] No training samples found in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mroot_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmeta_file_train\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    123\u001b[0m meta_data_train \u001b[38;5;241m=\u001b[39m add_extra_keys(meta_data_train, language, dataset_name)\n",
      "File \u001b[1;32m~\\KGO_Projects\\tts\\TTS\\TTS\\tts\\datasets\\formatters.py:162\u001b[0m, in \u001b[0;36mljspeech\u001b[1;34m(root_path, meta_file, **kwargs)\u001b[0m\n\u001b[0;32m    160\u001b[0m         cols \u001b[38;5;241m=\u001b[39m line\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m|\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    161\u001b[0m         wav_file \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(root_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwavs\u001b[39m\u001b[38;5;124m\"\u001b[39m, cols[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.wav\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 162\u001b[0m         text \u001b[38;5;241m=\u001b[39m cols[\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m    163\u001b[0m         items\u001b[38;5;241m.\u001b[39mappend({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m: text, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maudio_file\u001b[39m\u001b[38;5;124m\"\u001b[39m: wav_file, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspeaker_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: speaker_name, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mroot_path\u001b[39m\u001b[38;5;124m\"\u001b[39m: root_path})\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m items\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "from TTS.tts.datasets import load_tts_samples\n",
    "train_samples, eval_samples = load_tts_samples(\n",
    "    dataset_config,\n",
    "    eval_split=True,\n",
    "    eval_split_max_size=config.eval_split_max_size,\n",
    "    eval_split_size=config.eval_split_size,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
