{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5bec3ff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/stonk013/KGO_Projects/tts/ama_model/training\n",
      "C:/Users/stonk013/KGO_Projects/tts/ama_model/tts_train_dir\n",
      "ama-01.wav 48000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# BaseDatasetConfig: defines name, formatter and path of the dataset.\n",
    "from TTS.tts.configs.shared_configs import BaseDatasetConfig\n",
    "\n",
    "#//*** create model output path if needed\n",
    "output_path = \"tts_train_dir\"\n",
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)\n",
    "\n",
    "output_path = \"tts_train_dir\"\n",
    "training_dir = \"training\"\n",
    "output_path = os.path.join(os.path.join(os.getcwd(), output_path))\n",
    "output_path\n",
    "training_dir = os.path.join(os.path.join(os.getcwd(), training_dir)).replace(\"\\\\\",\"/\")\n",
    "print(str(training_dir))\n",
    "t_path = str(output_path).replace(\"\\\\\",\"/\")\n",
    "t_path\n",
    "print(t_path)\n",
    "\n",
    "import os\n",
    "import wave\n",
    "fulldir = os.path.join(output_path,\"wavs\")\n",
    "#//**** Get the sample rate of the first WAV file, assume all files share the same sample_rate\n",
    "for file_name in os.listdir(fulldir):\n",
    "    with wave.open(os.path.join(fulldir,file_name), \"rb\") as wave_file:\n",
    "        frame_rate = wave_file.getframerate()\n",
    "        print(file_name,frame_rate)\n",
    "        break\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5963789",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " > Training Environment:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " > Setting up Audio Processor...\n",
      " | > sample_rate:48000\n",
      " | > resample:False\n",
      " | > num_mels:80\n",
      " | > log_func:np.log\n",
      " | > min_level_db:-100\n",
      " | > frame_shift_ms:None\n",
      " | > frame_length_ms:None\n",
      " | > ref_level_db:20\n",
      " | > fft_size:1024\n",
      " | > power:1.5\n",
      " | > preemphasis:0.0\n",
      " | > griffin_lim_iters:60\n",
      " | > signal_norm:False\n",
      " | > symmetric_norm:True\n",
      " | > mel_fmin:0\n",
      " | > mel_fmax:8000\n",
      " | > pitch_fmin:1.0\n",
      " | > pitch_fmax:640.0\n",
      " | > spec_gain:1.0\n",
      " | > stft_pad_mode:reflect\n",
      " | > max_norm:4.0\n",
      " | > clip_norm:True\n",
      " | > do_trim_silence:True\n",
      " | > trim_db:60.0\n",
      " | > do_sound_norm:False\n",
      " | > do_amp_to_db_linear:True\n",
      " | > do_amp_to_db_mel:True\n",
      " | > do_rms_norm:False\n",
      " | > db_level:None\n",
      " | > stats_path:None\n",
      " | > base:2.718281828459045\n",
      " | > hop_length:256\n",
      " | > win_length:1024\n",
      " | > Found 12 files in C:\\Users\\stonk013\\KGO_Projects\\tts\\ama_model\\tts_train_dir\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " | > Backend: Torch\n",
      " | > Mixed precision: False\n",
      " | > Precision: float32\n",
      " | > Num. of CPUs: 8\n",
      " | > Num. of Torch Threads: 4\n",
      " | > Torch seed: 54321\n",
      " | > Torch CUDNN: True\n",
      " | > Torch CUDNN deterministic: False\n",
      " | > Torch CUDNN benchmark: False\n",
      " | > Torch TF32 MatMul: False\n",
      " > Start Tensorboard: tensorboard --logdir=C:\\Users\\stonk013\\KGO_Projects\\tts\\ama_model\\tts_train_dir\\run-August-10-2023_09+29PM-0000000\n",
      "\n",
      " > Model has 28259417 parameters\n",
      "\n",
      "\u001b[4m\u001b[1m > EPOCH: 0/1000\u001b[0m\n",
      " --> C:\\Users\\stonk013\\KGO_Projects\\tts\\ama_model\\tts_train_dir\\run-August-10-2023_09+29PM-0000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] Pre-computing phonemes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/12 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cache_path C:\\Users\\stonk013\\KGO_Projects\\tts\\ama_model\\tts_train_dir\\phoneme_cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|‚ñä         | 1/12 [00:00<00:08,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: √¶nd t…ôde…™ k√¶l ste…™t izi be…™ p…π…ôf…õs…ö …ôv k…ômjun…™ke…™ É…ôn √¶nd p…ôl…™t…™k…ôl …õksp…öt no äl…ôn h…™…°d…ôn spo äk w…™Œ∏  ås l…™v …ôba ät ha ä √∞…™s le…™t…™st …™nda…™tm…ônt k äd …ôf…õkt t…π åmps tÕ° É√¶ns…™z …™n tu Œ∏a äz…ônd tw…õnti f…î…π\n",
      "√¶nd t…ôde…™ k√¶l ste…™t izi be…™ p…π…ôf…õs…ö …ôv k…ômjun…™ke…™ É…ôn √¶nd p…ôl…™t…™k…ôl …õksp…öt no äl…ôn h…™…°d…ôn spo äk w…™Œ∏  ås l…™v …ôba ät ha ä √∞…™s le…™t…™st …™nda…™tm…ônt k äd …ôf…õkt t…π åmps tÕ° É√¶ns…™z …™n tu Œ∏a äz…ônd tw…õnti f…î…π\n",
      " [!] Character 'Õ°' not found in the vocabulary. Discarding it.\n",
      "cache_path C:\\Users\\stonk013\\KGO_Projects\\tts\\ama_model\\tts_train_dir\\phoneme_cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|‚ñà‚ñã        | 2/12 [00:01<00:05,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: √¶z njuz …ôv √∞…ô …™nda…™tm…ônt b…πo äk √∞…™s √¶ft…önun ju k äd w…îtÕ° É …™t l…™v wi juz √∞…ô …ôbk s…õv…ôn njuz √¶p t…ô s…õnd a ät √∞…™s no ät…™f…™ke…™ É…ôn t…ô l…™v\n",
      "cache_path C:\\Users\\stonk013\\KGO_Projects\\tts\\ama_model\\tts_train_dir\\phoneme_cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|‚ñà‚ñà‚ñå       | 3/12 [00:01<00:06,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: …™nv…õst…ô…°e…™t…öz …ë…π w…ök…™≈ã t…ô d…™t…öm…ôn √∞…ô k…îz …ôv …ô f…î…π …ôl…ë…πm fa…™…ö …™n s√¶n f…π√¶ns…™sko äz he…™z v√¶li √∞…ô fa…™…ö sp…ë…πkt …öa änd s…™ks √∞…™s m…î…πn…™≈ã …în o äk √¶nd …ëkte…™vi…ô st…πits f…î…π n…™…πba…™ b…™ld…™≈ãz w…ö d√¶m…™dÕ° íd √∞…ô hit k…π√¶kt ne…™b…ö…™≈ã w…™ndo äz √∞…ô b…™ld…™≈ã s…ôpo äzd t…ô bi …ô m…™kst jus m…ë…πk…™t …πe…™t ha äz…™≈ã p…π…ëdÕ° í…õkt w…ôz  ånd…ö k…ônst…π åk É…ôn\n",
      "cache_path C:\\Users\\stonk013\\KGO_Projects\\tts\\ama_model\\tts_train_dir\\phoneme_cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|‚ñà‚ñà‚ñà‚ñé      | 4/12 [00:02<00:04,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: ne…™b…öz to äld  ås √∞e…™ si ho äml…ôs pip…ôl …°o ä …™nsa…™d √¶z st…ë…πt fa…™…öz b…™f…î…π tu m ånŒ∏s …ô…°o ä √∞…ô p…π…õz…™d…ônt …ôv √∞…ô he…™z v√¶li ne…™b…öh äd …ôso ä Éie…™ É…ôn …πo ät …ô l…õt…ö t…ô √∞…ô s…™ti …ôba ät √∞…ô n åmb…ö …ôv fa…™…öz s…öa änd…™≈ã t…õnt k√¶mps …în …ëkte…™vi…ô st…πit\n",
      "cache_path C:\\Users\\stonk013\\KGO_Projects\\tts\\ama_model\\tts_train_dir\\phoneme_cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 5/12 [00:02<00:03,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: …™n s√¶n f…π√¶ns…™sko ä f√¶m…™liz l…™v…™≈ã …™n …πvz p…ë…πkt klo äs t…ô le…™k m…öst w…™l sun fe…™s p…ë…πk…™≈ã …πist…π…™k É…ônz\n",
      "cache_path C:\\Users\\stonk013\\KGO_Projects\\tts\\ama_model\\tts_train_dir\\phoneme_cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 6/12 [00:04<00:05,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: si vi …õs pl√¶nz t…ô le…™…îf fa…™v Œ∏a äz…ônd …™mpl…î…™iz √∞…ô d…π å…°st…î…π tÕ° Ée…™n s…õz …™ts t…πa…™…™≈ã t…ô k åt k…îsts √∞…ô le…™…îfs w…™l n…ët …ôf…õkt k åst…ôm…ö fe…™s…™≈ã …™mpl…î…™iz √∞e…™ w…™l mo ästli …ôf…õkt pip…ôl …™n k…î…πp…ö…™t …πo älz le…™d …îf w…ök…öz w…™l …π…™siv s…õv…ö…ôns pe…™ √¶nd b…õn…ôf…™ts √¶nd s…öv…™s…™z t…ô fa…™nd …ôn å√∞…ö dÕ° í…ëb …πi…°…ôl s…™n…ôm…ôz √∞…ô w…öldz s…õk…ônd l…ë…πdÕ° í…™st Œ∏i…ôt…ö tÕ° Ée…™n …™z a ät …ôv b√¶≈ãk…π…ôpsi …™ts p…õ…π…ônt k åmp…ôni sa…™nw…öld s…õz …™t h√¶z k åt f…î…π √¶nd …ô h√¶f b…™lj…ôn d…ël…öz …ôv d…õt …πe…™zd e…™t h ånd…π…™d m…™lj…ôn …™n nju …õkw…™ti k√¶p…™t…ôl √¶nd s…™kj ä…πd f…™n√¶ns…™≈ã f…ö w ån p…î…™nt s…õv…ôn w ån b…™lj…ôn d…ël…öz √∞…ô tÕ° Ée…™n fa…™ld f…ö b√¶≈ãk…π…ôpsi l√¶st s…õpt…õmb…ö √¶nd klo äzd d åz…ônz …ôv Œ∏i…ôt…öz …™≈ãklud…™≈ã w ån …™n b…ök…ôli √∞…ô p√¶nd…õm…™k w…ôz t åf …în muvi Œ∏i…ôt…öz b åt bl…ëkb åst…ö h…™ts √∞…™s s åm…ö la…™k b…ë…πbi √¶nd …ëp…ônha…™m…ö h…õlpt t…ön Œ∏…™≈ãz …öa änd\n",
      "cache_path C:\\Users\\stonk013\\KGO_Projects\\tts\\ama_model\\tts_train_dir\\phoneme_cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 7/12 [00:06<00:05,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: √∞…ô n√¶zd√¶k w…õnt da än s…™ksti tu √∞…ô …õs √¶nd pi l…îst tw…õlv p…î…™nts b åt √∞√¶t …™nd…õks …™z  åp tw…õnti w ån p…ös…õnt so ä f…ë…π √∞…™s j…™…π √∞√¶ts √∞…ô l…ë…πdÕ° í…™st …°e…™n …™n dÕ° í…ôla…™ …™n …ô kw…î…πt…ö …ôv …ô s…õntÕ° É…öi h…õlp …™z …ôve…™l…ôb…ôl …πa…™t na ä f…ö pip…ôl …™n √∞…ô be…™ …õ…πi…ô hu …ë…π o äv…ödu pe…™…™≈ã √∞…õ…π to älz …™ts Œ∏…πu f√¶st…π√¶k w…™tÕ° É …™z √∞…ô s…™st…ôm √∞√¶t tÕ° É…ë…πdÕ° í…™z d…πa…™v…öz hu k…π…îs √∞…ô to äl b…π…™dÕ° í …î…π juz …õni …ôv √∞…ô …™ksp…π…õs le…™nz √¶nd …πa…™t na ä ju …ë…π l äk…™≈ã la…™v √¶t s åm …ôv a ä…ö b…π…™dÕ° í…™z √∞…ô …π…™tÕ° Ém…ônd s√¶n …π…ëfa…™…õl b…π…™dÕ° í be…™ b…π…™dÕ° í s√¶n m…ëte…™o ä b…π…™dÕ° í Œ∏…π b…π…™dÕ° í …în √∞…ô …πa…™t h√¶z √∞…ô mo äst t…π√¶f…™k na ä √∞…™s p…πo ä…°…π√¶m …™n p…öt…™kj…ôl…ö …™z …°…™…πd t…ôw…î…πd lo ä …™≈ãk åm f√¶m…™liz. pip…ôl k…ôn fa…™nd a ät …™f √∞e…™ kw…ël…ôfa…™ ba…™ k…îl…™≈ã f√¶st…π√¶k s…öv…™s √¶nd √∞…õn …ôpla…™…™≈ã …înla…™n f…ö …ôs…™st…ôns h…™…πz ha ä …™t w…öks.\n",
      "cache_path C:\\Users\\stonk013\\KGO_Projects\\tts\\ama_model\\tts_train_dir\\phoneme_cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 8/12 [00:06<00:03,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: √∞√¶t w…ôz d…™sk åst ba…™ k…ë≈ã…°…π…ôsm…ôn …πo ä k…ën…ô √¶t w ån …ôv √∞…ô w…öldz l…ë…πdÕ° í…™st s…õma…™ k…ônd åkt…ö p…π…ôdus…öz …™n s ånive…™l t…ôde…™ e…™ bi si s…õv…ôn njuz sa äŒ∏ be…™ …π…™p…î…πt…ö z√¶k fw…õnte…™z w…ôz √∞…õ…π\n",
      "cache_path C:\\Users\\stonk013\\KGO_Projects\\tts\\ama_model\\tts_train_dir\\phoneme_cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 9/12 [00:07<00:02,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: …ô f…õd…ö…ôl …™nv…õst…ô…°e…™ É…ôn …™ntu t…õsl…ôz pa ä…ö st…™…π…™≈ã …™z na ä  ånd…öwe…™ √¶ft…ö d åz…ônz …ôv k…ômple…™nts f…π åm d…πa…™v…öz tu h ånd…π…™d ia…™ti Œ∏a äz…ônd vi…™k…ôlz …ë…π k åv…öd ba…™ √∞…ô …™nv…õst…ô…°e…™ É…ôn k…ë…π o än…öz k…ômple…™n …ôv luz…™≈ã pa ä…ö st…™…π…™≈ã √¶nd st…™…π…™≈ã k…ônt…πo äl …™n tu Œ∏a äz…ônd tw…õnti Œ∏…πi t…õsl…ô m…ëd…ôl Œ∏…πi s…™d√¶nz √¶nd m…ëd…ôl wa…™ s åvz √∞…ô n√¶ Én…ôl ha…™we…™ t…π√¶f…™k se…™fti √¶dm…™n…™st…πe…™ É…ôn s…õz √∞…õ…π …™z w ån …π…™p…î…πt …ôv …ô k…π√¶ É b åt no ä …™ndÕ° í…öiz f…π åm √∞…™s …™ Éu. f…õd…ö…ôl se…™fti …π…õ…°j…ôle…™t…öz pl√¶n t…ô l äk …™ntu m√¶nj…ôf√¶ktÕ° É…ö…™≈ã s…™v…õ…π…™ti √¶nd ha ä √∞…ô …™ Éu …ôk…öz …™n √∞…ô …™nv…õst…ô…°e…™ É…ôn\n",
      "cache_path C:\\Users\\stonk013\\KGO_Projects\\tts\\ama_model\\tts_train_dir\\phoneme_cache\n",
      "Text: \n",
      "cache_path C:\\Users\\stonk013\\KGO_Projects\\tts\\ama_model\\tts_train_dir\\phoneme_cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 11/12 [00:07<00:00,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: f…™l s…õz √∞…ô p…π…ëbl…ôm …™z n…ët junik t…ô o äkl…ônd √¶nd s√¶n f…π√¶ns…™sko ä iv…ôn sm…îl…ö s…™tiz la…™k s√¶n …π…ômo än …ë…π …™ksp…™…πi…ôns…™≈ã ha…™ ve…™k…ônsi …πe…™ts f…ö k…ôm…ö É…ôl …πil …™ste…™t\n",
      "cache_path C:\\Users\\stonk013\\KGO_Projects\\tts\\ama_model\\tts_train_dir\\phoneme_cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:09<00:00,  1.21it/s]\n",
      "\n",
      "\u001b[1m > TRAINING (2023-08-10 21:29:47) \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: √¶kt…ö z…õnde…™…ô t…ôde…™ po äst…™d …ô m…õs…™dÕ° í …π…™m…õmb…ö…™≈ã h…ö ko äst…ë…π √¶nd f…õlo ä o äkl…ônd ne…™t…™v √¶≈ã…°…ôs kla äd kla ädz f√¶m…™li …ôna änst h…™z d…õŒ∏ j…õst…öde…™ h…™z f√¶m…™li s…õd hi st…π å…°…ôld w…™Œ∏ √∞…ô d…õŒ∏ …ôv h…™z f…ë√∞…ö w…™tÕ° É h√¶p…ônd dÕ° í åst l√¶st wik √¶nd s åf…öd f…π åm m…õnt…ôl h…õlŒ∏ …™ Éuz z…õnde…™…ô √¶nd kla äd ko ä st…ë…πd …™n √∞…ô e…™tÕ° É bi o ä d…π…ëm…ô s…™…πiz juf…î…πi…ô √¶nd bo äŒ∏ …ôt…õnd…™d o äkl…ônd skul f…ö √∞…ô …ë…πts z…õnde…™ …πo ät …în …™nst…ô…°…π√¶m kwo ät a…™ no ä pip…ôl juz √∞…™s …™ksp…π…õ É…ôn …îft…ôn w…õn t…îk…™≈ã …ôba ät fo äks √∞e…™ l åv √∞e…™ k äd la…™t  åp …õni …πum √∞e…™ …õnt…öd b åt b…î…™ l…õt mi t…õl ju hi w…ôz √∞…ô b…õst √¶t …™t a…™d la…™k t…ô …π…™m…õmb…ö h…™m √∞√¶t we…™ kla äd w…ôz tw…õnti fa…™v j…™…πz o äld wi h√¶v p ät t…ô…°…õ√∞…ö …ô ho äl l…™st …ôv …πis…î…πs…™z f…ö …õniw ån dil…™≈ã w…™Œ∏ l…îs, …°…πif …î…π m…õnt…ôl h…õlŒ∏ …™ Éuz ju k…ôn fa…™nd lo äk…ôl …πis…î…πs…™z ba…™ …°o ä…™≈ã t…ô …ôbks…õv…ôn njuz d…ët k…ëm sl√¶ É te…™k √¶k É…ôn √¶nd …™f ju nid …™t √∞…ô su…™sa…™d √¶nd k…πa…™s…ôs la…™fla…™n k…ôn bi …πitÕ° Ét ba…™ da…™l…™≈ã na…™n e…™t e…™t\n",
      "\n",
      "\n",
      "> DataLoader initialization\n",
      "| > Tokenizer:\n",
      "\t| > add_blank: False\n",
      "\t| > use_eos_bos: False\n",
      "\t| > use_phonemes: True\n",
      "\t| > phonemizer:\n",
      "\t\t| > phoneme language: en-us\n",
      "\t\t| > phoneme backend: gruut\n",
      "\t| > 1 not found characters:\n",
      "\t| > Õ°\n",
      "| > Number of instances : 12\n",
      " | > Preprocessing samples\n",
      " | > Max text length: 908\n",
      " | > Min text length: 106\n",
      " | > Avg text length: 392.8181818181818\n",
      " | \n",
      " | > Max audio length: 4811245.0\n",
      " | > Min audio length: 645483.0\n",
      " | > Avg audio length: 2134389.1818181816\n",
      " | > Num. instances discarded samples: 1\n",
      " | > Batch group size: 0.\n",
      "Self.OutPath C:\\Users\\stonk013\\KGO_Projects\\tts\\ama_model\\tts_train_dir\\run-August-10-2023_09+29PM-0000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\stonk013\\Anaconda3\\envs\\tts\\lib\\site-packages\\trainer\\trainer.py\", line 1806, in fit\n",
      "    self._fit()\n",
      "  File \"C:\\Users\\stonk013\\Anaconda3\\envs\\tts\\lib\\site-packages\\trainer\\trainer.py\", line 1758, in _fit\n",
      "    self.train_epoch()\n",
      "  File \"C:\\Users\\stonk013\\Anaconda3\\envs\\tts\\lib\\site-packages\\trainer\\trainer.py\", line 1485, in train_epoch\n",
      "    for cur_step, batch in enumerate(self.train_loader):\n",
      "  File \"C:\\Users\\stonk013\\Anaconda3\\envs\\tts\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 633, in __next__\n",
      "    data = self._next_data()\n",
      "  File \"C:\\Users\\stonk013\\Anaconda3\\envs\\tts\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 1345, in _next_data\n",
      "    return self._process_data(data)\n",
      "  File \"C:\\Users\\stonk013\\Anaconda3\\envs\\tts\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\", line 1371, in _process_data\n",
      "    data.reraise()\n",
      "  File \"C:\\Users\\stonk013\\Anaconda3\\envs\\tts\\lib\\site-packages\\torch\\_utils.py\", line 644, in reraise\n",
      "    raise exception\n",
      "AssertionError: Caught AssertionError in DataLoader worker process 0.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"C:\\Users\\stonk013\\Anaconda3\\envs\\tts\\lib\\site-packages\\torch\\utils\\data\\_utils\\worker.py\", line 308, in _worker_loop\n",
      "    data = fetcher.fetch(index)\n",
      "  File \"C:\\Users\\stonk013\\Anaconda3\\envs\\tts\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 54, in fetch\n",
      "    return self.collate_fn(data)\n",
      "  File \"C:\\Users\\stonk013\\KGO_Projects\\tts\\TTS\\TTS\\tts\\datasets\\dataset.py\", line 464, in collate_fn\n",
      "    mel = prepare_tensor(mel, self.outputs_per_step)\n",
      "  File \"C:\\Users\\stonk013\\KGO_Projects\\tts\\TTS\\TTS\\tts\\utils\\data.py\", line 29, in prepare_tensor\n",
      "    return np.stack([_pad_tensor(x, pad_len) for x in inputs])\n",
      "  File \"C:\\Users\\stonk013\\KGO_Projects\\tts\\TTS\\TTS\\tts\\utils\\data.py\", line 29, in <listcomp>\n",
      "    return np.stack([_pad_tensor(x, pad_len) for x in inputs])\n",
      "  File \"C:\\Users\\stonk013\\KGO_Projects\\tts\\TTS\\TTS\\tts\\utils\\data.py\", line 20, in _pad_tensor\n",
      "    assert x.ndim == 2\n",
      "AssertionError\n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'tb_frame'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[1;32m~\\Anaconda3\\envs\\tts\\lib\\site-packages\\trainer\\trainer.py:1806\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1805\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1806\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mrank \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\tts\\lib\\site-packages\\trainer\\trainer.py:1758\u001b[0m, in \u001b[0;36mTrainer._fit\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mskip_train_epoch \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstart_with_eval:\n\u001b[1;32m-> 1758\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mrun_eval:\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\tts\\lib\\site-packages\\trainer\\trainer.py:1485\u001b[0m, in \u001b[0;36mTrainer.train_epoch\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1484\u001b[0m batch_num_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_loader)\n\u001b[1;32m-> 1485\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m cur_step, batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_loader):\n\u001b[0;32m   1486\u001b[0m     outputs, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_step(batch, batch_num_steps, cur_step, loader_start_time)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\tts\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    632\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 633\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    634\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\tts\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1345\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1344\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_task_info[idx]\n\u001b[1;32m-> 1345\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\tts\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1371\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m   1370\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[1;32m-> 1371\u001b[0m     \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1372\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\tts\\lib\\site-packages\\torch\\_utils.py:644\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    643\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 644\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[1;31mAssertionError\u001b[0m: Caught AssertionError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"C:\\Users\\stonk013\\Anaconda3\\envs\\tts\\lib\\site-packages\\torch\\utils\\data\\_utils\\worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"C:\\Users\\stonk013\\Anaconda3\\envs\\tts\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 54, in fetch\n    return self.collate_fn(data)\n  File \"C:\\Users\\stonk013\\KGO_Projects\\tts\\TTS\\TTS\\tts\\datasets\\dataset.py\", line 464, in collate_fn\n    mel = prepare_tensor(mel, self.outputs_per_step)\n  File \"C:\\Users\\stonk013\\KGO_Projects\\tts\\TTS\\TTS\\tts\\utils\\data.py\", line 29, in prepare_tensor\n    return np.stack([_pad_tensor(x, pad_len) for x in inputs])\n  File \"C:\\Users\\stonk013\\KGO_Projects\\tts\\TTS\\TTS\\tts\\utils\\data.py\", line 29, in <listcomp>\n    return np.stack([_pad_tensor(x, pad_len) for x in inputs])\n  File \"C:\\Users\\stonk013\\KGO_Projects\\tts\\TTS\\TTS\\tts\\utils\\data.py\", line 20, in _pad_tensor\n    assert x.ndim == 2\nAssertionError\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mSystemExit\u001b[0m                                Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "Cell \u001b[1;32mIn[2], line 101\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;66;03m# AND... 3,2,1... üöÄ\u001b[39;00m\n\u001b[1;32m--> 101\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\tts\\lib\\site-packages\\trainer\\trainer.py:1842\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1841\u001b[0m traceback\u001b[38;5;241m.\u001b[39mprint_exc()\n\u001b[1;32m-> 1842\u001b[0m \u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mSystemExit\u001b[0m: 1",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\tts\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2095\u001b[0m, in \u001b[0;36mInteractiveShell.showtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[0;32m   2092\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m exception_only:\n\u001b[0;32m   2093\u001b[0m     stb \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAn exception has occurred, use \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mtb to see \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   2094\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthe full traceback.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m-> 2095\u001b[0m     stb\u001b[38;5;241m.\u001b[39mextend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mInteractiveTB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_exception_only\u001b[49m\u001b[43m(\u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2096\u001b[0m \u001b[43m                                                     \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   2097\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2098\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   2099\u001b[0m         \u001b[38;5;66;03m# Exception classes can customise their traceback - we\u001b[39;00m\n\u001b[0;32m   2100\u001b[0m         \u001b[38;5;66;03m# use this in IPython.parallel for exceptions occurring\u001b[39;00m\n\u001b[0;32m   2101\u001b[0m         \u001b[38;5;66;03m# in the engines. This should return a list of strings.\u001b[39;00m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\tts\\lib\\site-packages\\IPython\\core\\ultratb.py:696\u001b[0m, in \u001b[0;36mListTB.get_exception_only\u001b[1;34m(self, etype, value)\u001b[0m\n\u001b[0;32m    688\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_exception_only\u001b[39m(\u001b[38;5;28mself\u001b[39m, etype, value):\n\u001b[0;32m    689\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Only print the exception type and message, without a traceback.\u001b[39;00m\n\u001b[0;32m    690\u001b[0m \n\u001b[0;32m    691\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    694\u001b[0m \u001b[38;5;124;03m    value : exception value\u001b[39;00m\n\u001b[0;32m    695\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 696\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mListTB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\tts\\lib\\site-packages\\IPython\\core\\ultratb.py:559\u001b[0m, in \u001b[0;36mListTB.structured_traceback\u001b[1;34m(self, etype, evalue, etb, tb_offset, context)\u001b[0m\n\u001b[0;32m    556\u001b[0m     chained_exc_ids\u001b[38;5;241m.\u001b[39madd(\u001b[38;5;28mid\u001b[39m(exception[\u001b[38;5;241m1\u001b[39m]))\n\u001b[0;32m    557\u001b[0m     chained_exceptions_tb_offset \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    558\u001b[0m     out_list \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 559\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    560\u001b[0m \u001b[43m            \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    561\u001b[0m \u001b[43m            \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    562\u001b[0m \u001b[43m            \u001b[49m\u001b[43m(\u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchained_exc_ids\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[0;32m    563\u001b[0m \u001b[43m            \u001b[49m\u001b[43mchained_exceptions_tb_offset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    564\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    565\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    566\u001b[0m         \u001b[38;5;241m+\u001b[39m chained_exception_message\n\u001b[0;32m    567\u001b[0m         \u001b[38;5;241m+\u001b[39m out_list)\n\u001b[0;32m    569\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out_list\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\tts\\lib\\site-packages\\IPython\\core\\ultratb.py:1396\u001b[0m, in \u001b[0;36mAutoFormattedTB.structured_traceback\u001b[1;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1394\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1395\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtb \u001b[38;5;241m=\u001b[39m etb\n\u001b[1;32m-> 1396\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mFormattedTB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1397\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\n\u001b[0;32m   1398\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\tts\\lib\\site-packages\\IPython\\core\\ultratb.py:1287\u001b[0m, in \u001b[0;36mFormattedTB.structured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1284\u001b[0m mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode\n\u001b[0;32m   1285\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose_modes:\n\u001b[0;32m   1286\u001b[0m     \u001b[38;5;66;03m# Verbose modes need a full traceback\u001b[39;00m\n\u001b[1;32m-> 1287\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVerboseTB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1288\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\n\u001b[0;32m   1289\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1290\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMinimal\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m   1291\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ListTB\u001b[38;5;241m.\u001b[39mget_exception_only(\u001b[38;5;28mself\u001b[39m, etype, value)\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\tts\\lib\\site-packages\\IPython\\core\\ultratb.py:1140\u001b[0m, in \u001b[0;36mVerboseTB.structured_traceback\u001b[1;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstructured_traceback\u001b[39m(\n\u001b[0;32m   1132\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1133\u001b[0m     etype: \u001b[38;5;28mtype\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1137\u001b[0m     number_of_lines_of_context: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m,\n\u001b[0;32m   1138\u001b[0m ):\n\u001b[0;32m   1139\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1140\u001b[0m     formatted_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat_exception_as_a_whole\u001b[49m\u001b[43m(\u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1141\u001b[0m \u001b[43m                                                           \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1143\u001b[0m     colors \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mColors  \u001b[38;5;66;03m# just a shorthand + quicker name lookup\u001b[39;00m\n\u001b[0;32m   1144\u001b[0m     colorsnormal \u001b[38;5;241m=\u001b[39m colors\u001b[38;5;241m.\u001b[39mNormal  \u001b[38;5;66;03m# used a lot\u001b[39;00m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\tts\\lib\\site-packages\\IPython\\core\\ultratb.py:1030\u001b[0m, in \u001b[0;36mVerboseTB.format_exception_as_a_whole\u001b[1;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[0;32m   1027\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tb_offset, \u001b[38;5;28mint\u001b[39m)\n\u001b[0;32m   1028\u001b[0m head \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_header(\u001b[38;5;28mstr\u001b[39m(etype), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlong_header)\n\u001b[0;32m   1029\u001b[0m records \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m-> 1030\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_records\u001b[49m\u001b[43m(\u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m etb \u001b[38;5;28;01melse\u001b[39;00m []\n\u001b[0;32m   1031\u001b[0m )\n\u001b[0;32m   1033\u001b[0m frames \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m   1034\u001b[0m skipped \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\tts\\lib\\site-packages\\IPython\\core\\ultratb.py:1098\u001b[0m, in \u001b[0;36mVerboseTB.get_records\u001b[1;34m(self, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[0;32m   1096\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m cf \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1097\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1098\u001b[0m         mod \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39mgetmodule(\u001b[43mcf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtb_frame\u001b[49m)\n\u001b[0;32m   1099\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m mod \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1100\u001b[0m             mod_name \u001b[38;5;241m=\u001b[39m mod\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'tb_frame'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from trainer import Trainer, TrainerArgs\n",
    "\n",
    "from TTS.config.shared_configs import BaseAudioConfig\n",
    "from TTS.tts.configs.shared_configs import BaseDatasetConfig\n",
    "from TTS.tts.configs.tacotron2_config import Tacotron2Config\n",
    "from TTS.tts.datasets import load_tts_samples\n",
    "from TTS.tts.models.tacotron2 import Tacotron2\n",
    "from TTS.tts.utils.text.tokenizer import TTSTokenizer\n",
    "from TTS.utils.audio import AudioProcessor\n",
    "\n",
    "# from TTS.tts.datasets.tokenizer import Tokenizer\n",
    "\n",
    "\n",
    "\n",
    "dataset_config = BaseDatasetConfig(\n",
    "    #formatter=\"vctk\", meta_file_train=\"\", language=\"en-us\", path=os.path.join(os.path.join(output_path,\"wavs\"))\n",
    "    formatter=\"ljspeech\", meta_file_train=\"metadata.csv\", language=\"en-us\", path=output_path\n",
    ")\n",
    "\n",
    "audio_config = BaseAudioConfig(\n",
    "    sample_rate=frame_rate,\n",
    "    do_trim_silence=True,\n",
    "    trim_db=60.0,\n",
    "    signal_norm=False,\n",
    "    mel_fmin=0.0,\n",
    "    mel_fmax=8000,\n",
    "    spec_gain=1.0,\n",
    "    log_func=\"np.log\",\n",
    "    ref_level_db=20,\n",
    "    preemphasis=0.0,\n",
    ")\n",
    "\n",
    "config = Tacotron2Config(  # This is the config that is saved for the future use\n",
    "    audio=audio_config,\n",
    "    batch_size=64,\n",
    "    eval_batch_size=16,\n",
    "    num_loader_workers=4,\n",
    "    num_eval_loader_workers=4,\n",
    "    run_eval=True,\n",
    "    test_delay_epochs=-1,\n",
    "    ga_alpha=0.0,\n",
    "    decoder_loss_alpha=0.25,\n",
    "    postnet_loss_alpha=0.25,\n",
    "    postnet_diff_spec_alpha=0,\n",
    "    decoder_diff_spec_alpha=0,\n",
    "    decoder_ssim_alpha=0,\n",
    "    postnet_ssim_alpha=0,\n",
    "    r=2,\n",
    "    attention_type=\"dynamic_convolution\",\n",
    "    double_decoder_consistency=False,\n",
    "    epochs=1000,\n",
    "    text_cleaner=\"phoneme_cleaners\",\n",
    "    use_phonemes=True,\n",
    "    phoneme_language=\"en-us\",\n",
    "    phoneme_cache_path=os.path.join(output_path, \"phoneme_cache\"),\n",
    "    print_step=25,\n",
    "    print_eval=True,\n",
    "    mixed_precision=False,\n",
    "    output_path=output_path,\n",
    "    datasets=[dataset_config],\n",
    ")\n",
    "\n",
    "# INITIALIZE THE AUDIO PROCESSOR\n",
    "# Audio processor is used for feature extraction and audio I/O.\n",
    "# It mainly serves to the dataloader and the training loggers.\n",
    "ap = AudioProcessor.init_from_config(config)\n",
    "\n",
    "# INITIALIZE THE TOKENIZER\n",
    "# Tokenizer is used to convert text to sequences of token IDs.\n",
    "# If characters are not defined in the config, default characters are passed to the config\n",
    "tokenizer, config = TTSTokenizer.init_from_config(config)\n",
    "\n",
    "# LOAD DATA SAMPLES\n",
    "# Each sample is a list of ```[text, audio_file_path, speaker_name]```\n",
    "# You can define your custom sample loader returning the list of samples.\n",
    "# Or define your custom formatter and pass it to the `load_tts_samples`.\n",
    "# Check `TTS.tts.datasets.load_tts_samples` for more details.\n",
    "train_samples, eval_samples = load_tts_samples(\n",
    "    dataset_config,\n",
    "    eval_split=False,\n",
    "    eval_split_max_size=config.eval_split_max_size,\n",
    "    eval_split_size=config.eval_split_size,\n",
    ")\n",
    "\n",
    "# INITIALIZE THE MODEL\n",
    "# Models take a config object and a speaker manager as input\n",
    "# Config defines the details of the model like the number of layers, the size of the embedding, etc.\n",
    "# Speaker manager is used by multi-speaker models.\n",
    "model = Tacotron2(config, ap, tokenizer)\n",
    "\n",
    "# INITIALIZE THE TRAINER\n",
    "# Trainer provides a generic API to train all the üê∏TTS models with all its perks like mixed-precision training,\n",
    "# distributed training, etc.\n",
    "trainer = Trainer(\n",
    "    TrainerArgs(), config, output_path, model=model, train_samples=train_samples, eval_samples=eval_samples\n",
    ")\n",
    "\n",
    "# AND... 3,2,1... üöÄ\n",
    "trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136e4434",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b995db4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
